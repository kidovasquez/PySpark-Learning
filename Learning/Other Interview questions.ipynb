{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d37ecd9e-9345-4b2c-866b-25cb9862c37a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1,),\n",
    "    (2,),\n",
    "    (3,),\n",
    "    (4,),\n",
    "    (5,),\n",
    "    (6,),\n",
    "    (7,),\n",
    "    (8,),\n",
    "    (9,),\n",
    "    (10,)\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"Number\"])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0638633-25a4-4238-8a8f-57bdfe22127a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016cf0eb-6fc8-42a7-91d0-44890378283c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df = df.withColumn(\"Even Number\", when(col(\"Number\") % 2 == 0, col('Number'))).withColumn(\"Odd Number\", when(col(\"Number\") % 2 == 1, col('Number'))).drop(\"Number\").select(\"Even Number\", \"Odd Number\")\n",
    "\n",
    "display(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "726cd8b4-ee42-44a3-add3-0d6ecfed6ede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data1 = [45, 12, 78, 23, 56, 89, 34, 67, 90, 11]\n",
    "max = 0\n",
    "for i in data1:\n",
    "    if max < i:\n",
    "        max = i\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02ea4cd8-8f73-497c-babe-77ae3e535683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "country_data = [\n",
    "    (\"india\",),\n",
    "    (\"australia\",),\n",
    "    (\"england\",)\n",
    "]\n",
    "\n",
    "country_schema = ['country']\n",
    "\n",
    "country_df = spark.createDataFrame(country_data, country_schema)\n",
    "\n",
    "display(country_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90c98248-8a0e-473d-b52e-faa2d857dbcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import concat_ws\n",
    "cross_df = country_df.crossJoin(country_df.withColumnRenamed(\"Country\", \"Country2\"))\n",
    "\n",
    "# Filter out same country matches\n",
    "filtered_df = cross_df.filter(col(\"Country\") < col(\"Country2\"))\n",
    "\n",
    "# Concatenate Country1 and Country2\n",
    "matches_df = filtered_df.withColumn(\"Matches\", concat_ws(\" vs \", col(\"Country\"), col(\"Country2\"))).select(\"Matches\")\n",
    "\n",
    "# Show Output\n",
    "matches_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55eb0ab7-f2cd-44c4-b6ff-eb79b3f0dd06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "country_df.createOrReplaceTempView(\"Matches\")\n",
    "\n",
    "# SQL Query to Generate Match Combinations\n",
    "query = \"\"\"\n",
    "SELECT m1.Country || ' vs ' || m2.Country AS Matches\n",
    "FROM Matches m1\n",
    "JOIN Matches m2 ON m1.Country < m2.Country\n",
    "ORDER BY Matches\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL Query\n",
    "result_df = spark.sql(query)\n",
    "\n",
    "# Show Output\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02c2705-0783-4315-8e59-212ba2e824b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dictionary problem\n",
    "Input= 'aaabbbccddeeeee'\n",
    "dict_v = {} \n",
    "for i in Input:\n",
    "    dict_v[i] = dict_v.get(i, 0) + 1\n",
    "\n",
    "print(dict_v)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Other Interview questions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
